MAIN SCRIPT LINE-BY-LINE EXPLANATION
=====================================

LINE 1-12: IMPORTS SECTION
---------------------------
Line 1: import pandas as pd
- Imports pandas library for data manipulation and analysis

Line 2: from dataset_engineering.cross_val import Set, WalkForwardFull, plot_tscv, RollingYearlyValidation, ExpandingWindowValidation
- Imports custom cross-validation classes and functions for time series validation
- Set: Data class for defining train/val/test periods
- WalkForwardFull: Walk-forward cross-validation implementation
- plot_tscv: Function to visualize time series cross-validation splits
- RollingYearlyValidation, ExpandingWindowValidation: Additional CV strategies

Line 3: import tensorflow as tf
- Imports TensorFlow deep learning framework

Line 4: from neural_nets.baseline import Params
- Imports the Params dataclass that contains all model hyperparameters and configuration

Line 5: import keras_tuner as kt
- Imports Keras Tuner for automated hyperparameter optimization

Line 6: from finetuning.hypermodel import HyperModel
- Imports custom HyperModel class that defines the hyperparameter search space

Line 7: from finetuning.analyse import analyse_trials_opt
- Imports function to analyze and rank hyperparameter optimization trials

Line 8: from criterion.metrics import Recall, F1Score
- Imports custom metric implementations for model evaluation

Line 9: from dataset_engineering.source import compute_data
- Imports function that loads and preprocesses the raw financial data

Line 10: from neural_nets.source import train_infer_nn, train_infer_process
- Imports main training and inference functions for neural networks

Line 11: import random
- Imports random module for reproducible randomness

Line 12: import numpy as np
- Imports NumPy for numerical operations

Line 13: from sklearn.metrics import classification_report
- Imports scikit-learn's classification report for detailed performance metrics

Line 14: from dataclasses import dataclass
- Imports dataclass decorator for creating structured data classes

LINE 16-20: SET DATA CLASS DEFINITION
-------------------------------------
Line 16: @dataclass
- Decorator to create a data class with automatic __init__, __repr__, etc.

Line 17: class Set:
- Defines a data class to represent time periods for train/validation/test sets

Line 18: idx: int
- Index number of the time period fold

Line 19: start: int
- Starting index of the time period

Line 20: end: int
- Ending index of the time period

LINE 23: MAIN EXECUTION CHECK
-----------------------------
Line 23: if __name__ == '__main__':
- Ensures the following code only runs when script is executed directly (not imported)

LINE 26: DATA LOADING
--------------------
Line 26: data, dates, target, features = compute_data()
- Calls compute_data() function to load and preprocess financial data
- Returns: preprocessed DataFrame, date index, target variable name, feature list

LINE 28-31: EXPERIMENT CONFIGURATION
-----------------------------------
Line 28: days_ahead = 10
- Sets prediction horizon to 10 days in the future
- This means the model will predict what happens 10 days from now

Line 29: n_steps = 60
- Sets the sequence length (lookback window) to 60 time steps
- Model will use 60 previous observations to make predictions

Line 30: type_learn = 'classification'
- Sets the learning task type to classification (vs regression)
- Model will predict binary outcomes (high/low volatility periods)

Line 31: method_aggregate_target = 'return'
- Defines how to compute the target variable from raw data
- 'return' means calculating percentage returns over the prediction horizon

LINE 32-33: HYPERPARAMETER CONFIGURATION
---------------------------------------
Line 32: config_hp = ['lr', 'dropout', 'batch_size', 'threshold', 'fix_outliers', 'hidden_dim', 'n_steps'] # 'opt', 'l1', 'fix_outliers', 'scale_y', 'allow_missing_ts'
- Defines which hyperparameters to optimize during tuning
- Includes: learning rate, dropout, batch size, classification threshold, etc.
- Commented out parameters show other options that were tested

LINE 35-46: TASK-SPECIFIC CONFIGURATION
--------------------------------------
Line 35: if type_learn == 'regression':
- Conditional block for regression task setup

Line 36: criterion = tf.keras.losses.MeanSquaredError
- Sets loss function to Mean Squared Error for regression

Line 37-46: elif type_learn == 'classification':
- Conditional block for classification task setup

Line 38: # Maximize recall in order to not miss the uncertainty time-steps
- Comment explaining the goal: maximize recall to catch all uncertain periods

Line 39: criterion = tf.keras.losses.BinaryCrossentropy(from_logits=True)
- Sets loss function to Binary Cross-entropy with logits for classification

Line 40: # metric = tf.keras.metrics.AUC(curve="PR")
- Commented out: Alternative metric (Area Under Precision-Recall Curve)

Line 41: metric=tf.keras.metrics.F1Score(average="weighted")
- Sets evaluation metric to weighted F1-Score

Line 42: metric.direction = 'max'
- Specifies that higher F1-Score values are better (maximize)

Line 43: output_dim = 2
- Sets output dimension to 2 for binary classification (2 classes)

LINE 45-50: PARAMETER INITIALIZATION
-----------------------------------
Line 45: params = Params(input_dim=len(features), output_dim=output_dim, criterion=criterion, layer='LSTM',
Line 46:          activation='relu', n_steps=n_steps, days_ahead=days_ahead,
Line 47:          n_hidden=1, hidden_dim=4, epochs=100, batch_size=16, patience_es=5, dropout=0.3,
Line 48:          method_aggregate_target=method_aggregate_target, target=target, type_learn=type_learn, metric=metric)
- Creates Params object with all model hyperparameters
- input_dim: Number of input features
- LSTM layer with ReLU activation
- Single hidden layer with 4 units
- 100 training epochs with early stopping patience of 5
- Batch size 16, dropout 0.3

LINE 50-53: REPRODUCIBILITY SETUP
---------------------------------
Line 50: random.seed(params.seed)
- Sets random seed for Python's random module

Line 51: np.random.seed(params.seed)
- Sets random seed for NumPy

Line 52: tf.random.set_seed(params.seed)
- Sets random seed for TensorFlow operations

LINE 55-56: PROJECT NAMING
--------------------------
Line 55: project_name = "__".join(config_hp)
- Creates project name by joining hyperparameter names with "__"

Line 56: directory = 'finetune_results'
- Sets directory name for saving hyperparameter tuning results

LINE 58-63: CROSS-VALIDATION SETUP
----------------------------------
Line 58: # cv = WalkForwardFull(data, start_test=pd.to_datetime('2019-12-31'), gap=days_ahead,
Line 59: #     # fix_start=True, val_size=3 * 20, test_size=3 * 20)
- Commented out: Alternative walk-forward cross-validation setup

Line 60: cv = RollingYearlyValidation(data, num_of_year_per_fold = 5, val_months=12)
- Sets up rolling yearly validation with 5-year training periods and 12-month validation

Line 61: # cv = ExpandingWindowValidation(data, val_months=3)
- Commented out: Alternative expanding window validation

Line 62: # plot_tscv(cv, data, target, params, features)
- Commented out: Function to visualize cross-validation splits

LINE 64: PROJECT NAME EXTENSION
------------------------------
Line 64: project_name = f'flag_return_ASW2YR_ahead{days_ahead}_all_val2025_85_f103_' + project_name
- Extends project name with specific experiment details
- Indicates: flag prediction, ASW2YR target, prediction horizon, validation year, etc.

LINE 66-85: HYPERPARAMETER TUNING SETUP
--------------------------------------
Line 66: auto_tune = False
- Flag to disable automatic hyperparameter tuning (manual mode)

Line 67: use_cv = False
- Flag to disable cross-validation (single train/val/test split)

Line 68-85: if auto_tune: block
- Hyperparameter tuning configuration (currently disabled)
- Sets up Bayesian optimization with Keras Tuner
- Defines search space and optimization objective
- Configures maximum trials and search strategy

LINE 87: TARGET DISPLAY
---------------------
Line 87: print(target)
- Prints the target variable name for verification

LINE 88-91: TUNER EXECUTION
--------------------------
Line 88-91: tuner.search() call
- Executes hyperparameter search (when auto_tune=True)
- Passes data, features, target, and other training parameters
- Performs cross-validation during search

Line 91: trials = analyse_trials_opt()
- Analyzes completed hyperparameter trials and ranks them by performance

LINE 93-97: MANUAL PARAMETER OVERRIDES
-------------------------------------
Line 93: else:
- Block executed when auto_tune=False (manual hyperparameter setting)

Line 94: no_missing_ts = True if 'no_missing_ts' in config_hp else False
- Sets flag for handling missing time steps based on configuration

Line 95: scale_target = True if 'scale_y' in config_hp else False
- Sets flag for target variable scaling based on configuration

Line 96: add_transf = True if 'add_transf' in config_hp else False
- Sets flag for additional transformations (square root) based on configuration

Line 97: fix_outliers = True if 'fix_outliers' in config_hp else False
- Sets flag for outlier handling based on configuration

LINE 99-104: MANUAL HYPERPARAMETER SETTING
-----------------------------------------
Line 99: params.lr = 1e-4
- Sets learning rate to 0.0001

Line 100: params.l1reg = 0.0001
- Sets L1 regularization strength

Line 101: params.n_steps = 30
- Override sequence length to 30 steps

Line 102: params.threshold = 0.85
- Sets classification threshold to 0.85 (85th percentile)

Line 103: params.patience_es = 10
- Sets early stopping patience to 10 epochs

Line 104: params.epochs = 100
- Sets maximum training epochs to 100

LINE 106: DATE INDEX PREPARATION
-------------------------------
Line 106: dates = pd.to_datetime(data.index)
- Converts data index to datetime format for date operations

LINE 108-111: TRAINING PERIOD DEFINITION
---------------------------------------
Line 108: train_start = pd.to_datetime('2002-01-01')
- Sets training period start date to January 1, 2002

Line 109: train_end = pd.to_datetime('2024-12-31')
- Sets training period end date to December 31, 2024

Line 111: val_start = pd.to_datetime('2002-01-01')
- Sets validation period start date to January 1, 2002

Line 112: val_end = pd.to_datetime('2024-12-31')
- Sets validation period end date to December 31, 2024
- Note: Same as training period (likely for out-of-sample testing)

LINE 115-118: DATE INDEX CONVERSION
----------------------------------
Line 115: train_start_idx = dates.searchsorted(train_start)
- Finds index position of training start date in the date series

Line 116: train_end_idx = dates.searchsorted(train_end, side='right') - 1
- Finds index position of training end date (right-aligned)

Line 117: val_start_idx = dates.searchsorted(val_start)
- Finds index position of validation start date

Line 118: val_end_idx = dates.searchsorted(val_end, side='right') - 1
- Finds index position of validation end date

LINE 120-125: DATE VALIDATION
-----------------------------
Line 120-125: if statement with multiple conditions
- Validates that all date indices are within valid ranges
- Ensures training start < training end
- Ensures validation start < validation end
- Checks that indices don't exceed data length

LINE 126-128: SET CREATION
-------------------------
Line 126: train_dates = Set(idx=0, start=dates[train_start_idx], end=dates[train_end_idx])
- Creates Set object for training period with actual dates

Line 127: val_dates = Set(idx=0, start=dates[val_start_idx], end=dates[val_end_idx])
- Creates Set object for validation period with actual dates

Line 128: test_dates =Set(idx=0, start=dates[train_start_idx], end=dates[train_end_idx])
- Creates Set object for test period (currently same as training period)

LINE 130-140: MODEL TRAINING EXECUTION
-------------------------------------
Line 130: if use_cv:
- Conditional block for cross-validation training (currently False)

Line 131-140: Cross-validation training call
- Would execute train_infer_process with cross-validation
- Includes all preprocessing flags and parameters

Line 142: else:
- Block executed for single train/val/test split (current mode)

Line 143-150: Single split training call
- Executes train_infer_process with defined train/val/test sets
- Includes all preprocessing parameters
- Returns trained model, predictions, and results

LINE 152: CLASSIFICATION REPORT
------------------------------
Line 152: print(classification_report(targets_val, preds_val))
- Prints detailed classification performance metrics
- Shows precision, recall, F1-score for each class
- Provides overall performance summary

SUMMARY OF SCRIPT PURPOSE:
=========================
This main script orchestrates a complete machine learning pipeline for financial time series forecasting:

1. LOADS AND PREPROCESSES financial market data
2. CONFIGURES the prediction task (classification of high-volatility periods)
3. SETS UP hyperparameter optimization framework (currently disabled)
4. DEFINES training/validation/test periods
5. TRAINS neural network models (LSTM-based)
6. EVALUATES model performance on validation data
7. GENERATES predictions and performance reports

The script is designed to predict "uncertainty periods" in financial markets - specifically periods where significant price movements (above 85th percentile) are likely to occur within the next 10 days. This is formulated as a binary classification problem using LSTM networks with financial indicators as features.